'use strict';(function(){const b={};b.doc={id:'id',field:['title','content'],store:['title','href','parent']};const a=FlexSearch.create(b);window.geekdocSearchIndex=a,a.add({id:0,href:'/vision/lung-abnormalities-detection-xray/intro/',title:"Giới thiệu bài toán - Phát hiện và khanh vùng bất thường trên phổi từ ảnh x-quang",parent:"Phát hiện bất thường trên phổi",content:"Kỹ thuật chẩn đoán hình ảnh chụp X-quang diễn ra rất phổ biến trong các xét nghiệm y tế tại bệnh viện. Hình ảnh X-quang phổi có giá trị trong việc phát hiện, chẩn đoán bệnh, đánh giá mức độ nặng, đánh giá các biến chứng hô hấp, theo dõi đáp ứng điều trị và chẩn đoán phân biệt. Dựa vào bộ dữ liệu được công bố trong cuộc thi VinBigData Chest X-ray Abnormalities Detection chúng tôi xây dựng các thuật toán trí tuệ nhân tạo để phát hiện và khoanh vùng 14 loại tổn thương khác nhau trên hình ảnh X-quang phổi.\nCuộc thi chẩn đoán với ảnh X-quang phổi của VinBigdata\n"}),a.add({id:1,href:'/vision/lung-abnormalities-classification-xray/intro/',title:"Giới thiệu bài toán - Phân loại bất thường trên phổi từ ảnh x-quang",parent:"Phân loại tổn thương phổi",content:"1. Chuẩn đoán các bệnh phổi trên ảnh X-quang 1.1. Giới thiệu Chụp X-quang ngực (Chest X-ray – CXR) là một trong những xét nghiệm ảnh phổ biến nhất trong chẩn đoán nhiều bệnh khác nhau liên quan đến phổi và tim, với hàng triệu scans được thực hiện toàn cầu mỗi năm. Nhiều bệnh trong số đó, như Pneumothorax (Phổi tràn khí), có thể gây chết người nếu không được chẩn đoán đủ nhanh và chính xác. Một hệ thống chẩn đoán có sự hỗ trợ của máy tính (computer-aided diagnosis – CAD) có thể chẩn đoán chính xác những quan sát phổ biến nhất từ ảnh chụp X-quang ngực sẽ mang lại lợi ích đáng kể cho nhiều thực hành lâm sàng. Trong báo cáo này, chúng tôi nghiên cứu bài toán phân loại đa nhãn (multi-label classification) cho ảnh chụp X-quang ngực bằng cách sử dụng mạng nơ-ron tích chập (convolutional neural networks – CNNs).\nMột số ví dụ về ảnh chụp X-quang ngực\nNhững nghiên cứu gần đây đang tập trung khai thác những tiến bộ trong học máy, đặc biệt là học sâu, để xây dựng một nhóm hệ thống CAD mới để phân loại và xác định vị trí các bệnh thường gặp ở lồng ngực từ hình ảnh CXR. Một số lý do đằng sau sự biến đổi này:\n  Thứ nhất, việc giải thích CXR để chẩn đoán chính xác bệnh lý là rất khó. Ngay cả những bác sĩ X quang được đào tạo bài bản cũng có thể dễ dàng mắc sai lầm do những thách thức trong việc phân biệt các loại bệnh lý khác nhau, nhiều bệnh lý thường có các đặc điểm hình ảnh giống nhau. Do đó, một phương pháp có thể phân loại và xác định chính xác vị trí các bệnh thường gặp ở lồng ngực có thể được sử dụng như một đầu đọc thứ hai để hỗ trợ quá trình ra quyết định của bác sĩ X quang và giúp giảm sai số chẩn đoán. Nó cũng giải quyết tình trạng thiếu chuyên môn chẩn đoán trong các lĩnh vực mà bác sĩ X quang hạn chế hoặc không có sẵn.\n  Thứ hai, một hệ thống như vậy có thể được sử dụng như một công cụ sàng lọc giúp giảm thời gian chờ đợi của bệnh nhân trong bệnh viện và cho phép các bên cung cấp dịch vụ chăm sóc phản ứng kịp thời với các tình huống khẩn cấp sớm hơn hoặc để tăng tốc quy trình làm việc chẩn đoán hình ảnh.\n  Một số ứng dụng của Deep Learning trong phân tích ảnh y tế\n Thứ ba, mạng nơron sâu, đặc biệt là CNN, đã cho thấy hiệu suất đáng kể đối với các ứng dụng khác nhau trong phân tích hình ảnh y tế, bao gồm cả nhiệm vụ giải đoán CXR.  Một số phương pháp tiếp cận dựa trên học sâu (deep learning – DL) đã được đề xuất để phân loại bệnh phổi và chứng minh rằng chúng có thể đạt được hiệu quả tương đương con người. Tuy nhiên, hầu hết tất cả các phương pháp này đều nhằm mục đích phát hiện một số bệnh cụ thể như viêm phổi, lao, hoặc ung thư phổi. Trong khi đó, việc xây dựng một DL framework thống nhất để phát hiện chính xác sự hiện diện của nhiều bệnh lý lồng ngực phổ biến từ chụp X quang phổi vẫn là một nhiệm vụ khó khăn, đòi hỏi nhiều nỗ lực nghiên cứu. Đặc biệt, chúng tôi nhận ra rằng các bộ phân loại đa nhãn tiêu chuẩn thường bỏ qua kiến ​​thức chuyên ngành (domain knowledge). Ví dụ, trong trường hợp dữ liệu CXR, làm thế nào để tận dụng các phân loại lâm sàng của các mô hình bệnh tật và cách xử lý các nhãn không chắc chắn (uncertainty label) vẫn còn là câu hỏi mở, chưa nhận được nhiều sự quan tâm nghiên cứu. Điều này thúc đẩy chúng tôi xây dựng và thử nghiệm một vài mô hình dự đoán dựa trên CNN để giải thích CXR, trong đó sự phụ thuộc giữa các nhãn (labels dependencies) và thông tin không chắc chắn được tính đến trong quá trình training và inference. Cụ thể, chúng tôi phát triển một số phương pháp tiếp cận dựa trên DL đưa các ý tưởng về conditional training và label smoothing thành một phương pháp training mới để phân loại 14 bệnh phổi phổ biến và các quan sát.\n2. Bài toán phân loại bất thường trên phổi Trong dự náy VN AIDr, chúng tôi xây dựng hệ thống đánh giá khả năng cho 5 bất thường trên ảnh X-quang phổi, với mong muốn hệ thống này có thể trợ giúp bác sĩ trong quá trình chẩn đoán triệu chứng từ ảnh y tế, hạn chế việc bỏ sót triệu chứng. Hệ thống phân loại tổn thương phổi được chúng tôi xây dựng dựa trên bộ dữ liệu lớn CheXpert của Đại học Stanford.\nWebsite bộ dữ liệu và cuộc thi CheXpert\n"}),a.add({id:2,href:'/nlp/vn-accent/intro/',title:"Giới thiệu bài toán - Thêm dấu tiếng Việt",parent:"Thêm dấu cho báo cáo y tế",content:"Bài toán thêm dấu tiếng Việt giải quyết việc thêm dấu cho các văn bản tiếng Việt không dấu. Trên thực tế, bài toán này đã được ứng dụng rất hiệu quả trong trình duyệt Cốc Cốc nhắm tiết kiệm thời gian nhập văn bản của người dùng và nhận được nhiều hưởng ứng tích cực. Trong dự án này, chúng tôi thiết kế và thử nghiệm một hệ thống thêm dấu tiếng Việt cho báo cáo y tế. Hệ thống được ứng dụng trong phần mềm VN AIDr nhằm giúp bác sĩ tiết kiệm thời gian gõ văn bản y tế, ví dụ như nhận xét tình trạng của bệnh nhân. Chúng tôi hy vọng hệ thống này có thể rút ngắn thời gian nhập liệu và góp phần giảm tải áp lực cho bác sĩ.\nVới dữ liệu khổng lồ các bài viết tiếng Việt lấy từ Wikipedia, kết hợp với dữ liệu bài viết từ các trang web về y học, chúng tôi huấn luyện các mô hình ngôn ngữ ngram và các mô hình dựa trên học sâu để dự đoán và thêm dấu cho các văn bản y học. Các bước thiết kế mô hình, chuẩn bị dữ liệu, huấn luyện và kiểm thử được chúng tôi trình bày trong các mục dưới. Chúng tôi cũng triển khai và thử nghiệm thực tế các mô hình huấn luyện được trên phần mềm VN AIDr.\n"}),a.add({id:3,href:'/intro/',title:"Giới thiệu dự án",parent:"VN AIDr",content:'Bạn có thể xem giới thiệu về dự án tại Trang chủ.\nTrang này sẽ tự động được điều hướng đến trang chủ. Nếu các bạn không được điều hướng, vui lòng click vào liên kết phía trên.\nwindow.location.href = "/";  '}),a.add({id:4,href:'/vision/lung-abnormalities-classification-xray/',title:"Phân loại tổn thương phổi",parent:"VAD Vision - Xử lý ảnh y tế",content:""}),a.add({id:5,href:'/nlp/vn-accent/',title:"Thêm dấu cho báo cáo y tế",parent:"VAD NLP - Xử lý ngôn ngữ tự nhiên",content:""}),a.add({id:6,href:'/posts/',title:"Tin tức",parent:"VN AIDr",content:""}),a.add({id:7,href:'/vision/lung-abnormalities-detection-xray/data-prep/',title:"Chuẩn bị dữ liệu - Phát hiện và khanh vùng bất thường trên phổi từ ảnh x-quang",parent:"Phát hiện bất thường trên phổi",content:"1. Thông tin về nguồn dữ liệu Chúng tôi sử dụng các dữ liệu được tải về và tiền xử lý từ website của cuộc thi VinBigData Chest X-ray Abnormalities Detection. Theo website chính thống của VinBigdata, hình ảnh được thu thập từ bệnh viện Trung ương Quân đội 108 và Bệnh viện Đại học Y Hà Nội, 100% dữ liệu được nặc danh hoá (toàn bộ thông tin định danh người bệnh đã được xoá bỏ hoặc thay thế bởi giá trị ngẫu nhiên) và chỉ giữ lại các thông tin cần thiết, phục vụ việc phân tích và xử lý hình ảnh. Mỗi hình ảnh cuộc thi cung cấp đều được đọc bởi các bác sĩ chẩn đoán hình ảnh đầu ngành tại Việt Nam. Đối với dữ liệu đào tạo, mỗi ca chụp được gán nhãn độc lập bởi 3 bác sĩ. Trong khi đó, đối với dữ liệu đánh giá, mỗi ca chụp được gán nhãn bởi hội đồng gồm 5 bác sĩ.\n2. Trực quan hoá dữ liệu với t-SNE Trực quan hoá dữ liệu với t-SNE\n3. Xoá nhãn No finding Dữ liệu ban đầu gồm 15000 ảnh, nhưng trong đó có chứa nhiều ảnh với nhãn \u0026ldquo;No finding\u0026rdquo;, tức là không có bất thường nào trong ảnh. Vì vậy, chúng tôi thực hiện loại bỏ những ảnh không chứa bất thường nào, cuối cùng thu được tập dữ liệu gồm 4394 ảnh. Các nhãn được giữ lại gồm: Aortic enlargement, Atelectasis, Calcification, Cardiomegaly, Consolidation, .iltration, Lung Opacity, Nodule/Mass, Other lesion, Pleural effusion, Pleural thickening, Pneumothorax, Pulmonary fibrosis. Tiếp đó, chúng tôi chia tập dữ liệu này thành 2 tập nhỏ là tập huấn luyện (training set) gồm 3515 ảnh và tập giám sát (validation set) gồm 879 ảnh.\nCác thao tác chuẩn bị dữ liệu\n"}),a.add({id:8,href:'/vision/lung-abnormalities-classification-xray/data-prep/',title:"Chuẩn bị dữ liệu - Phân loại bất thường trên phổi từ ảnh x-quang",parent:"Phân loại tổn thương phổi",content:"1. Bộ dữ liệu CheXpert bao gồm 224316 ảnh chụp X-quang ngực của 65240 bệnh nhân được lấy từ bênh viện Stanford. Bộ dataset được thu thập từ tháng 10/2002 đến thành 7/2017 với cả bệnh nhân nội trú và ngoại trú cùng với các báo cáo X-quang liên quan.\nCác thông tin trong báo cáo X-quang sẽ được trích xuất, phân loại và tổng hợp để gán nhãn cho 14 quan sát trên phổi. Mỗi quan sát sẽ ứng với một đặc điểm khác thường của phổi. Mỗi quan sát sẽ được gán nhãn dương tính (positive), âm tính (negative), hoặc không chắc chắn (uncertain). (0 for negative, -1 for uncertain, and 1 for positive).\nChi tiết bộ dataset CheXpert\nChúng tôi chỉ tập trung vào việc đánh giá 5 trong 14 quan sát, được lựa chọn dựa trên mức độ quan trọng và phổ biến trên lâm sàng:\n (a) Xẹp phổi (Atelectasis) (b) Tim to (Cardiomegaly) (c) Đông đặc phổi (Consolidation) (d) Phù nề (Edema) (e) Tràn dịch màng phổi (Pleural Effusion)  2. Phân chia dữ liệu thử nghiệm Dữ liệu được chia thành 2 tập là tập huấn luyện (training set) với 223414 ảnh và tập giám sát (validation set) với 234 ảnh. Chúng tôi thực hiện đánh giá các thử nghiệm trên tập giám sát này.\n"}),a.add({id:9,href:'/nlp/vn-accent/data-prep/',title:"Chuẩn bị dữ liệu - Thêm dấu tiếng Việt",parent:"Thêm dấu cho báo cáo y tế",content:"1. Thu thập và tiền xử lý dữ liệu Dữ liệu dùng cho bài toán này được chúng tôi thu thập từ 2 nguồn chính: (1) Wikipedia và (2) dữ liệu bài viết trên yhocvn.net và benhvien108.vn.\nCác nguồn dữ liệu được sử dụng\n  Với Wikipedia: Dữ liệu được tải về từ dumps.wikimedia.org và trích xuất văn bản với gói wikiextractor. Tiếp đó dữ liệu được tiền xử lý và trích xuất được 4315334 câu. Nhằm tiết kiệm thời gian, chúng tôi lấy dữ liệu đã được xử lý sẵn từ trang này.\n  Với các trang yhocvn.net và benhvien108.vn: Chúng tôi cào được 19.5 nghìn bài viết từ yhocvn.net và hơn 1400 bài viết từ benhvien108.vn. Sau khi qua bước tiền xử lý, chúng tôi trích xuất được 455549 câu.\n  Các bước tiền xử lý bao gồm:\n Tách các câu dựa vào các dấu chấm câu. Với mỗi câu: loại bỏ các chữ số, dấu câu, các kí tự đặc biệt, chỉ giữ lại các từ tạo nên bởi các chữ cái tiếng Việt và tiếng Anh, ngăn cách chúng bởi 1 dấu cách. Chuyển các câu về chữ thường. Chuẩn hoá dấu câu: Trong các văn bản tiếng Việt, vị trí chữ cái bỏ dấu có thể không đồng nhất. Ví dụ với chữ \u0026ldquo;hoà\u0026rdquo;, có văn bản viết \u0026ldquo;hoà\u0026rdquo;, cũng có văn bản viết là \u0026ldquo;hòa\u0026rdquo;. Chúng tôi thực hiện đưa vị trí bỏ dấu về một chuẩn chung. Trong trường hợp này, cả \u0026ldquo;hoà\u0026rdquo; và \u0026ldquo;hoà\u0026rdquo; đều được chuẩn hoá lại thành \u0026ldquo;hoà\u0026rdquo;. Loại bỏ các câu có dưới 10 từ và lớn hơn 200 từ rồi ghi ra tệp văn bản. Tạo dữ liệu không dấu bằng cách loại bỏ dấu câu thông qua mã nguồn từ aivivn.com.  Mã nguồn tiền xử lý dữ liệu:\n https://github.com/VNOpenAI/vn-accent/blob/master/preprocess_data/Preprocess_data_Wikipedia.ipynb. https://github.com/VNOpenAI/vn-accent/blob/master/preprocess_data/Preprocess_data_yhocvn_net_benhvien108_vn.ipynb.  2. Chia dữ liệu Phương pháp chia dữ liệu\nCác dữ liệu từ bước trên, sau quá trình xử lý được gộp vào nhau, trộn ngẫu nhiên và chia thành 3 tập: tập huần luyện (training set) gồm 4750883 câu, tập giám sát (validation set) gồm 10000 câu và tập kiểm thử (test set) gồm 10000 câu.\nMã nguồn chia dữ liệu: https://github.com/VNOpenAI/vn-accent/blob/master/preprocess_data/split_data.py\n"}),a.add({id:10,href:'/vision/lung-abnormalities-detection-xray/',title:"Phát hiện bất thường trên phổi",parent:"VAD Vision - Xử lý ảnh y tế",content:""}),a.add({id:11,href:'/vision/',title:"VAD Vision - Xử lý ảnh y tế",parent:"VN AIDr",content:""}),a.add({id:12,href:'/vision/skin-lesion-segmentation/intro-and-data/',title:"Giới thiệu bài toán và dữ liệu - Khoanh vùng tổn thương da",parent:"Phân vùng tổn thương da",content:"1. Giới thiệu bài toán. Phân đoạn ảnh y tế là vấn đề quan trọng trong các ứng dụng chuẩn đoán lâm sàng. Các ứng dụng của phân đoạn ảnh y tế giúp các bác sĩ tập trung hơn vào vùng bị tổn thương, giúp chuẩn đoán của bác sĩ trở lên dễ dàng hơn, chính xác hơn. Ngoài ra một trong các ứng dụng quan trọng của bài toán này là giúp đưa ra bằng chứng xác thực hơn, đang tin cậy hơn khi các mô hình AI đưa ra quyết định.\nMột trong nhưng vấn đề khó của phân đoạn ảnh y tế là không có sẵn lượng dữ liệu đủ lớn, chất lượng tốt và được gán nhãn, lý do là dữ liệu về ảnh y tế là nguồn dữ liệu nhạy cảm, yêu cầu người gán nhãn cần có kiến thức chuyên môn. Dựa trên những lý do đó, nhóm chúng tôi lựa chọn bài toán phân đoạn vùng da bị tổn thương , hỗ trợ trong chuẩn đoạn ảnh y tế - như là một phần trong VN-AIDr.\n2. Dữ liệu 2.1. Chuẩn bị dữ liệu Như đề cập trước giới hạn về nguồn dữ liệu là một vấn đề khó, cuộc thi ISIC2018_task1 cung cấp một lượng dữ liệu chất lượng đã được gán nhãn bởi các chuyên gia y tế. Tập dữ liệu do ban tổ chức cung cấp bao gồm tập ảnh train-validation-test, nhưng do cuộc thi đã kết thúc nên không thể lấy được tập test của ban tổ chức, chúng tôi quyết định sử dụng tập validation của ban tổ chức làm tập dữ liệu test và tập dữ liệu train của ban tổ chức sẽ chia làm hai để huấn luyện và lựa chọn mô hình.\nDữ liệu bao gồm:\n 2051 ảnh huấn luyện 500 ảnh tập giám sát 1000 ảnh kiểm định  ISIC_task1\n2.2. Tiền xử lý dữ liệu Với mô hình thử nghiệm khác nhau đều sử dụng chung cách thức xử lý dữ liệu.\nÁp dụng các phương pháp làm giàu và chuẩn hóa dữ liệu thông thường:\nData augmentation\n"}),a.add({id:13,href:'/nlp/vn-accent/n-grams/',title:"Mô hình N-grams - Thêm dấu tiếng Việt",parent:"Thêm dấu cho báo cáo y tế",content:"1. Mô hình 1.1. Mô hình N-grams N-grams được hiểu đơn giản là tần suất xuất hiện của n kí tự (từ) liên tiếp xuất hiện trong dữ hiêu\nMột số mô hình n-grams phổ biến\n  unigram, mô hình với n=1, tức là ta sẽ tính tần suất xuất hiện của một kí tự (từ), như: \u0026ldquo;k\u0026rdquo;, \u0026ldquo;a\u0026rdquo;,\u0026hellip;\n  bigrams với n=2 , là mô hình được sử dụng nhiều trong việc phân tích các hình thái cho ngôn ngữ\n  trigrams với n-3, với n càng lớn thì độ chính xác càng cao tuy nhiên đi kèm với đó thì độ phức tạp cũng lớn hơn\n  Để xây dựng một mô hình n-gram, ban đầu người ta dựa trên một tập dữ liệu huấn luyện( Tranning set). Sau khi mô hình được xây dựng, ta tiến hành kiểm tra mô hình dựa trên một tập dữ liệu test. Việc kiểm tra tốt nhất là sử dụng một tập dữ kiệu không có trong tập huấn luyện. Dựa vào việc kiểm tra này mà ta có thể biết được mô hình có tốt hay khôngx.\nMô hình N-gram:\n Để tính xác suất của một câu: W1W2\u0026hellip;.Wk\u0026hellip;.Wn. Theo công thức Bayes ta sẽ tính bằng cách:  \n Tuy nhiên, công thức trên có độ phức tạp lớn, vì vậy người ta thường sử dụng công thức Markov:  \nTrong đó:  \nDo khi tính xác suất có nhiều trường hợp sẽ gặp các cụm n-grams chưa xuất hiện hoặc do sự phân bố không đều trong tập huấn luyện sẽ dẫn tới việc tính toán không chính xác. Vì vậy người ta đưa ra phương pháp làm mịn để khắc phục vấn đề này\nMột số phương pháp làm mịn phổ biến:\n  Discounting: giảm xác suất các cụm n-grams có xác suất lớn hơn 0 để bù cho các cụm n-grams chưa xuất hiện\n  Back-off: tính xác suất các cụm n-grams chưa xuất hiện bằng các cụm ngắn hơn và có xác suất lớn hơn 0\n  Interpolation: tính xác suất của tất cả các cụm n-grams bằng các cụm ngắn hơn\n  Làm mịn bằng phương pháp Kneser – Ney smoothing (Interpolation).\n  Kneser-Ney là phương pháp chủ yếu được sử dụng để tính toán phân bố xác suất của n-grams trong một tài liệu dựa trên những tính toán đã có.\n  Kneser-Ney được coi là phương pháp hiệu quả nhất để làm mịn do việc sử dụng các chiết khấu tuyệt đối bằng cách trừ đi một giá trị cố định từ điều kiện về tần số bậc thấp của xác suất để bỏ qua n-grams với tần số thấp hơn. Đây là phương pháp hiệu quả với bigrams và các mô hình n-grams cao hơn.\n  Một ví dụ phổ biến để minh họa các khái niệm đằng sau phương pháp này là tần số Bigrams cảu cụm \u0026ldquo;San Francisco\u0026rdquo;. Nếu nó xuất hiện nhiều lần trong một ngữ liệu huấn luyện, tần số của unigrams \u0026ldquo;Francisco\u0026rdquo; cũng sẽ cao. Dựa vào chỉ có tần số unigrams để dự đoán các tần số của n-grams sẽ dẫn đến kết quả sai lệch. Tuy nhiên, Kneser-Ney mịn chỉnh này bằng cách xem xét các tần số của unigram liên quan đến những từ ở trước.\n  Công thức Kneser – ney:\n  \n\n\n1.2. Thuật toán tìm kiếm Trong xử lý ngôn ngữ tự nhiên, như các bài toán dịch máy hay bài toán tạo tiêu đề đều có thể đưa về bài toán sinh chuỗi từ.\nCác mô hình sinh kiểu này thường tính xác suất xuất hiện của từng từ trong chuỗi từ ở đầu ra, vì vậy cần một thuật toán giải mã để tìm ra chuỗi từ có xác suất lớn nhất. Trong project này, chúng tôi đưa ra hai thuật toán cơ bản để tìm kiếm chuỗi từ, đó là thuật toán tham ăn (greedy) và thuật toán beam search.\nKhi sử dụng các mô hình ngôn ngữ hay các mạng nở ron hồi quy, thì đầu ra của các mô hình này là các từ trong từ điển và xác suất xuất hiện các từ đó trong ngữ cảnh tương ứng. Thuật toán tìm kiếm sẽ tìm trên toàn bộ các chuỗi này và tìm ra chuỗi từ có xác suất xuất hiện lớn nhất. Kích thước của từ điển phụ thuộc vào bài toán, thường là vài trăm, vài nghìn hoặc thậm chí vài triệu từ. Bài toán tìm kiếm này có độ phức tạp tăng theo hàm mũ của độ dài câu, là bài tóan NP-đủ, vì vậy không thể giải đúng được.\nTrong thực tế, các phương pháp heuristic được sử dụng để tìm nghiệm xấp xỉ \u0026ldquo;đủ tốt\u0026rdquo; cho bài toán này.\nThuật toán tham ăn\nỞ giải thuật tìm kiếm tham ăn, tại mỗi bước tìm kiếm, chọn ra trong tập dự đoán từ nào có xác suất cao nhất. Sau đó lặp lại quá trình trên.\nƯu điểm của thuật toán này chính là tốc độ, trong khi nhược điểm là độ chính xác không hề cao, kết quả có thể khác xa kết quả tối ưu. Do chỉ cần sai một từ thì các từ tiếp theo sẽ bị ảnh hưởng nhiều.\nThuật toán beam search\nLà một thuật toán tìm kiếm theo chiều rộng.\nThay vì chỉ lấy một trường hợp có xác suất cao nhất tại mỗi bước, beam search mở rộng trường tìm kiếm bằng cách giữ lại k khả năng có xác suất cao nhất, với k là hằng số được lựa chọn. Các bước tiếp theo lặp lại trên k mẫu trước đó, và nhưng sau đó cũng chỉ giữ lại k mẫu cho bước tiếp theo. Cứ như vậy cho tới bước cuối cùng thì chọn mẫu có xác suất cao nhất trong k mẫu.\n\nKết quả thực nghiệm Bài toán thêm dấu được thực hiện theo các bước như sau:\n  Xây dựng mô hình Trigrams để đưa ra xác suất xuất hiện 1 từ nếu biết 2 từ đứng trước nó\n  Đối với mỗi từ Tiếng Việt không dấu, tiến hành generate tất cả các trường hợp có thể điền dấu cho từ\n  Sử dụng thuật toán tham ăn hoặc thuật toán beam search để lấy ra được câu cho xác suất lớn nhất\n  Test thử kết quả\n  Trong project này, chúng tôi thử nghiệm 2 mô hình phổ biến đó là mô hình 3-gram và 2-gram. Kết quả dưới đây là độ chính xác được tính trên tập validation với các tham số khác nhau của thuật toán beam search.\n   N_gram N_beam Val_score Seconds/sentence Test score Model size     2grams 1 0.8231 8.5  41Mb    2 0.8905 14.65      3 0.9138 15      4 0.9216 16.5      5 0.9258 18.3 0.9221     6 0.9273 18.5      7 0.9282 18.9     3grams 1 0.884 9      2 0.9128 15.5      3 0.9309 14.35      4 0.9369 19.5      5 0.9411 25.5 0.9401 441Mb    6 0.9438 26.5      7 0.9453 31.9      Tham khảo   https://viblo.asia/p/language-modeling-mo-hinh-ngon-ngu-va-bai-toan-them-dau-cau-trong-tieng-viet-1VgZveV2KAw?fbclid=IwAR27jOzmETv8zUj-idE5uMh7BGuKQqvOMtnTRpAdqVhhVwDHXbuTfYy59J0\n  https://machinelearningmastery.com/beam-search-decoder-natural-language-processing\n  "}),a.add({id:14,href:'/vision/skin-lesion-segmentation/models-and-experiments/',title:"Mô hình và thử nghiệm - Khoanh vùng tổn thương da",parent:"Phân vùng tổn thương da",content:"1. Mô hình 1.1. U-Net Một trong những mạng phổ biến nhất của bài toán đoạn ảnh là mô hình U-Net, và nhiều biến thể của mô hình U-Net.\nU-Net\nChúng tôi đã thử nghiệm lại mô hình này như những bước tiếp cận ban đầu. cấu trúc mô hình đã được sửa lại cho phù hợp với bài toán, hàm kích hoạt đầu ra là sigmoid cho đầu ra hai lớp.\n1.2. Double U-Net Mô hình cải tiến của U-Net, với kiến trúc mạng gồm hai mạng con, gần giống với hai mạng U-Net nối tiếp. đều có dạng encoder - decoder. Ở phần decoder2 có concatenate với skip-connections của decoder 1. Đầu ra của mạng bao gồm đầu ra của 2 mạng con. Trong bài báo gốc, tác giả chỉ ra rằng cả hai đầu ra đều có thể sử dụng để phân vùng ảnh, mạng con thứ 2 có tác dụng như là tinh chỉnh lại đầu ra. Một cải tiến nữa của U-Net là sử dụng ASPP.\nDoubleU-net\n2. Thử nghiệm và kết quả Cả 2 mô hình đều sử dụng :\n Hàm mục tiêu sử dụng: Dice loss. Độ đo: Mean intersection of union (Mean IoU).  Thuật toán huấn luyện Adame với tốc độ học $10^{-5}$. Sau 80 epochs với cùng tập dữ liệu và cùng một cách tiền xử lý.\n   Mô hình U-Net Double U-Net     Mean IoU 0.79 0.82    Kết quả cuối cùng mô hình tốt nhất trên tập kiểm thử là IOU = 0.79.\nKết quả chạy thử mô hình trên tập kiểm thử (test set)\nTham khảo [1] Origin paper: DoubleU-Net: A Deep Convolutional Neural Network for Medical Image Segmentation\n[2] ASPP block :DeepLab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected CRFs\n[3] Repository 2020-CBMS-DoubleU-Net\n[4] Data: ISIC2018_task1 Lesion Boundary Segmentaion \n"}),a.add({id:15,href:'/vision/lung-abnormalities-detection-xray/models-and-experiments/',title:"Mô hình và thử nghiệm - Phát hiện và khanh vùng bất thường trên phổi từ ảnh x-quang",parent:"Phát hiện bất thường trên phổi",content:"1. Mô hình Mô hình chúng tôi thử nghiệm cho bài toán này là YOLOv5. Dù đang trong quá trình phát triển, tài liệu về mô hình chưa đầy đủ, và cũng chưa có bài báo chính thức nào, nhiều thử nghiệm cho thấy YOLOv5 đạt kết quả rất tốt. Trong repository chứa mã nguồn của YOLOv5 tại ultralytics/yolov5, tác giả đã thực hiện một thử nghiệm để so sánh các phiên bản YOLOv5 với nhau và với EfficientDet, một mạng SOTA cho phát hiện vật.\nCác thử nghiệm YOLOv5\nChúng tôi lựa chọn mô hình YOLOv5x - mô hình đạt độ chính xác cao nhất để tiến hành huấn luyện cho bài toán này.\n2. Thử nghiệm Sau khi huấn luyện 30 epochs trên bộ dữ liệu đã chuẩn bị, mô hình đạt kết quả tốt nhất tại epoch 23 là mAP@0.5 = 0.320, mAP@.5:.95 = 0.140.\nGiám sát quá trình huấn luyện\nKết quả chạy thử mô hình với một số ảnh như sau:\nKết quả chạy thử mô hình YOLOv5 cho bài toán phát hiện bất thường trên phổi\n"}),a.add({id:16,href:'/vision/skin-lesion-segmentation/',title:"Phân vùng tổn thương da",parent:"VAD Vision - Xử lý ảnh y tế",content:""}),a.add({id:17,href:'/vision/lung-abnormalities-classification-xray/models-and-experiments/',title:"Thiết kế mô hình và thử nghiệm - Phân loại bất thường trên phổi từ ảnh x-quang",parent:"Phân loại tổn thương phổi",content:"1. Bài toán Multi-Label Classification Bài toán Multi-Label Classification bắt nguồn từ việc thử nghiệm vấn đề phân loại văn bản, trong đó mỗi tài liệu có thể thuộc về một số chủ đề được xác định trước đồng thời.\nMulti-Label Classification trong ảnh y tế, đặc biệt là ảnh X-quang ngực là một vấn đề quan trọng. Ví dụ một bức ảnh chụp phổi có thể có đồng thời nhiều triệu chứng/ bệnh khác nhau như tim to, phổi đông đặc, phổi tràn khí, v.v. Trong bài toán Multi-Label Classification, tập huấn luyện bao gồm các cá thể, mỗi cá thể được liên kết với một tập nhãn và nhiệm vụ là dự đoán các tập nhãn của các cá thể mới thông qua phân tích các cá thể được train với các tập nhãn đã biết.\nMulti-Class Classification vs Multi-Label Classification\nSự khác biệt giữa Multi-Class Classification và Multi-Label Classification là trong các bài toán nhiều lớp, các lớp loại trừ lẫn nhau, trong khi đối với các bài toán nhiều nhãn, mỗi nhãn đại diện cho một nhiệm vụ phân loại khác nhau, nhưng các nhiệm vụ có liên quan với nhau. Ví dụ, phân loại nhiều lớp đưa ra giả định rằng mỗi mẫu được gán cho một và chỉ một nhãn: một loại trái cây có thể là táo hoặc lê nhưng không phải cả hai cùng một lúc. Trong khi đó, một ví dụ của phân loại nhiều nhãn có thể là một văn bản có thể nói về bất kỳ tôn giáo, chính trị, tài chính hoặc giáo dục nào cùng một lúc hoặc không có nội dung nào trong số này.\nCó hai hướng tiếp cận để giải quyết bài toán Multi-Label Classification:\n  Flat Multi-Label Classification (FMC): Tính tổng quát của các bài toán đa nhãn chắc chắn sẽ làm cho việc học trở nên khó khăn hơn. Một cách tiếp cận trực quan để giải quyết vấn đề nhiều nhãn là phân tách nó thành nhiều bài toán phân loại nhị phân độc lập (mỗi loại một). Giả định là các nhãn loại trừ lẫn nhau. Chúng ta không xem xét bất kỳ mối tương quan nào giữa các lớp trong phương pháp này.\n  Hierarchical Multi-Label Classification (HMC): Là một biến thể của bài toán classification, khi mỗi sample có thể có nhiều hơn một nhãn và tất cả các nhãn được tổ chức phân cấp dưới dạng trong một cây/ Direct Acyclic Graph (DAG), để khai thác sự phụ thuộc giữa các nhãn dựa vào kiến thức chuyên ngành.\n  Trong báo cáo này, chúng tôi sẽ thực hiện thử nghiệm cả hai phương pháp trên với 4 mô hình khác nhau trên tập data CheXpert.\n2. Flat Multi-Label Classification (FMC) 2.1. Tiền xử lý dữ liệu Các phương pháp tiền xử lý dữ liệu được sử dụng trong thử nghiệm với các mô hình FMC bao gồm:\n  Cân bằng Histogram\n  Gaussian Blur\n  Padding và Resize ảnh về kích thước (512,512)\n  Chuẩn hóa ảnh (mean=128, std=64)\n  2.2. Tăng cường dữ liệu Gia tăng dữ liệu là một phương pháp đơn giản nhưng rất quan trọng để giúp giảm được hiện tượng quá khớp (over-fitting) trong quá trình huấn luyện các mạng học sâu do sự giới hạn về số lượng dữ liệu.\nTrong dự án này, các phương pháp augment sau sẽ được sử dụng:\n  Random Translate – dịch ngẫu nhiên ảnh\n  Random Scale – thay đổi kích thước ảnh\n  Random Rotate – Xoay ảnh\n  Các phương pháp augment trên sẽ được sử dụng chung cho thử nghiệm với các mô hình FMC.\n2.3. FMC-I (Architecture I) Kiến trúc mô hình FMC-I\n2.4. FMC-II (Architecture II) Kiến trúc mô hình FMC-II\n3. Hierarchical Multi-Label Classification (HMC) 3.1. Label smoothing regularization (LSR) cho các uncertainty Một vấn đề thách thức khác trong phân loại đa nhãn của CXR là chúng ta có thể không có toàn quyền truy cập vào các nhãn thực cho tất cả các hình ảnh đầu vào do tập dữ liệu đào tạo cung cấp. Các bộ dữ liệu CXR quy mô lớn được tạo ra với sự thật cơ bản đáng tin cậy hơn, chẳng hạn như CheXpert và MIMIC-CXR. Tuy nhiên, việc gắn nhãn các bộ dữ liệu này phụ thuộc rất nhiều vào các chuyên gia, điều này khiến nhiều hình ảnh CXR có nhãn không chắc chắn (uncertainty label). Điều này chủ yếu là do sự mơ hồ không thể tránh khỏi trong các báo cáo y tế. Một số cách tiếp cận đã được đề xuất trong để giải quyết những mẫu này. Ví dụ: tất cả chúng có thể bị bỏ qua (U-Bỏ qua), tất cả được ánh xạ tới dương (U-Ones) hoặc tất cả được ánh xạ tới âm (U-Zeros). U-ignore không thể sử dụng danh sách đầy đủ các nhãn trên toàn bộ tập dữ liệu, cả U-Ones và U-Zeros đều mang lại một cải tiến tối thiểu trên CheXpert. Điều này có thể là do việc đặt tất cả các nhãn không chắc chắn thành 1 hoặc 0 chắc chắn sẽ tạo ra rất nhiều nhãn sai, dẫn đến việc đào tạo mô hình sai.\nLấy ý tưởng từ [1], trong bài báo này, chúng tôi sử dụng phương pháp tên Label smoothing regularization (LSR) để xử lý tốt hơn các uncertainty label. Mục tiêu chính là để khai thác số lượng lớn các CXR không chắc chắn và đồng thời, để ngăn mô hình dự đoán quá tự tin về các ví dụ đào tạo có thể chứa dữ liệu gắn nhãn sai. Cụ thể, cách tiếp cận U-ones được làm mềm bằng cách ánh xạ mỗi nhãn độ không đảm bảo (−1) với một số ngẫu nhiên gần bằng 1. Cách tiếp cận U-ones + LSR được đề xuất hiện ánh xạ nhãn ban đầu yk (i) thành\n $$ \\bar{y}_{k}^{(i)}=\\left\\{\\begin{array}{ll} u, \u0026 \\text { if } y_{k}^{(i)}=-1 \\\\ y_{k}^{(i)}, \u0026 \\text { otherwise } \\end{array}\\right. $$ Trong đó u ∼ U (0.55; 0.85) là biến ngẫu nhiên được phân phối đồng đều giữa 0.55 và 0.85. Tương tự, phương pháp tiếp cận U-zeros + LSR để làm mềm U-zeros bằng cách đặt mỗi uncertainty label thành một số ngẫu nhiên u ∼ U (0; 0.3).\n3.2. Tiền xử lý dữ liệu Các phương pháp tiền xử lý dữ liệu được sử dụng trong thử nghiệm với các mô hình HMC bao gồm:\n  Resize ảnh về kích thước (256x256)\n  Chuẩn hóa ảnh (mean=128, std=64)\n  LSR\n  3.3. Tăng cường dữ liệu Trong báo cáo này, các phương pháp augment sau sẽ được sử dụng:\n  Random Translate – dịch ngẫu nhiên ảnh\n  Random Scale – thay đổi kích thước ảnh\n  Random Rotate – Xoay ảnh\n  Các phương pháp augment trên sẽ được sử dụng chung cho thử nghiệm với các mô hình HMC.\n3.4. Mô hình Fully Associative Ensemble Learning (FAEL) [2] Kiến trúc mô hình FAEL\n3.5. Mô hình Conditional Training [1]** Hệ thống phân cấp bệnh\nMô hình Conditional Training [1] đề xuất một phương pháp huấn luyện mới cho bài toán Multi-Label Classification ảnh X-quang ngực có kết hợp:\n  Một quy trình huấn luyện có điều kiện (conditional training) dựa trên hệ thống phân cấp bệnh được định nghĩa trước bởi các chuyên gia.\n  Sử dụng kỹ thuật LSR cho các uncertainty label.\n  Minh họa ý tưởng chính đằng sau conditional training\nConditional training khai thác hệ thống phân cấp qua 2 bước.\n  Bước đầu tiên, được gọi là conditional training, nhằm mục đích học các mối quan hệ phụ thuộc giữa parent và child labels và tập trung vào việc phân biệt các nhãn cấp dưới, đặc biệt là các nhãn lá. Trong bước này, CNN được pretrained trên một tập huấn luyện chứa tất cả các parent labels dương để phân loại các child labels.\n  Trong bước thứ hai, transfer learning sẽ được khai thác. Cụ thể, đóng băng tất cả các lớp của pretrained model ngoại trừ lớp fully connected cuối cùng và sau đó retrain trên tập dữ liệu đầy đủ. Giai đoạn training này để nâng cao khả năng dự đoán các parent labels của mạng.\n  4. Thử nghiệm và Kết quả 4.1. Thử nghiệm 1 - Thử nghiệm 1 train và so sánh chất lượng của các mô hình “flat classification” trên tập data CheXpert.\n    Cardiomegaly Edema Consolidation Atelectasis P.Effusion Mean     ResNeSt50 0.858 0.937 0.913 0.859 0.921 0.898   ResNeSt101 0.863 0.922 0.935 0.862 0.926 0.902   EfficientB4 0.862 0.930 0.929 0.869 0.928 0.904   DenseNet121 0.850 0.926 0.925 0.856 0.915 0.894    Bảng 1. Kết quả thử nghiệm với 4 backbone khác nhau của kiến trúc “flat classification I”*\n    Cardiomegaly Edema Consolidation Atelectasis P.Effusion Mean     ResNeSt50 0.850 0.925 0.929 0.859 0.934 0.899   ResNeSt101 0.844 0.931 0.935 0.875 0.917 0.900   EfficientB4 0.809 0.937 0.894 0.867 0.919 0.885   DenseNet121 0.867 0.916 0.924 0.839 0.903 0.890    Bảng 2. Kết quả thử nghiệm với 4 backbone khác nhau của kiến trúc “flat classification II”*\n4.1. Thử nghiệm 2 - Thử nghiệm 2 train và so sánh chất lượng của các mô hình “hierarchical classification” trên tập data CheXpert\n- Kết quả thử nghiệm với mô hình FAEL (fully associative ensemble learning)\n    Cardiomegaly Edema Consolidation Atelectasis P.Effusion Mean     ResNeSt50-B 0.729 0.895 0.898 0.835 0.928 0.857   ResNeSt101-B 0.760 0.921 0.878 0.823 0.937 0.864   EfficientB4-B 0.740 0.896 0.904 0.809 0.931 0.856   DenseNet121-B 0.639 0.912 0.830 0.864 0.928 0.835   ResNeSt50-F 0.767 0.873 0.904 0.862 0.931 0.867   ResNeSt101-F 0.769 0.889 0.895 0.850 0.937 0.868   EfficientB4-F 0.786 0.860 0.918 0.814 0.930 0.862   DenseNet121-F 0.726 0.914 0.867 0.858 0.930 0.859    Bảng 3. Kết quả thử nghiệm với 4 backbone khác nhau của mô hình FAEL*\n- Kết quả thử nghiệm với mô hình Conditional Training:\n    Cardiomegaly Edema Consolidation Atelectasis P.Effusion Mean     ResNeSt50 0.773 0.912 0.874 0.797 0.879 0.847   ResNeSt101 0.790 0.914 0.883 0.786 0.905 0.856   EfficientB4 0.763 0.928 0.858 0.773 0.888 0.842   DenseNet121 0.793 0.918 0.886 0.790 0.884 0.854    Bảng 4. Kết quả thử nghiệm với 4 backbone khác nhau của mô hình Conditional Training*\n4.3. Thử nghiệm 3 - Thử nghiệm 3 thực hiện ensemble các kiến trúc đã mô tả ở trên với 4 backbone khác nhau và so sánh chất lượng các mô hình ensemble với nhau.\n    Cardiomegaly Edema Consolidation Atelectasis P.Effusion Mean     FlatCls-I 0.872 0.938 0.943 0.873 0.929 0.911   FlatCls-II 0.867 0.932 0.940 0.875 0.926 0.908   FAEL 0.793 0.895 0.916 0.866 0.942 0.882   Conditional Training 0.792 0.924 0.904 0.801 0.903 0.865    Bảng 5. Kết quả thử nghiệm với 4 mô hình ensemble từ các backbone khác nhau*\n"}),a.add({id:18,href:'/nlp/',title:"VAD NLP - Xử lý ngôn ngữ tự nhiên",parent:"VN AIDr",content:""}),a.add({id:19,href:'/platform/',title:"VN AIDr Platform - Phần mềm xử lý ảnh y tế nguồn mở",parent:"VN AIDr",content:"1. Tổng quan Chúng tôi xây dựng phần mềm xử lý ảnh y tế VN AIDr như một giao diện để tương tác với các thuật toán và mô hình đã huấn luyện. Toàn bộ mã nguồn VN AIDr được xây dựng trên nguyên tắc đơn giản, dễ dùng, dễ mở rộng để sử dụng với các mô hình và nhiệm vụ khác. Phía dưới đây là demo giao diện chương trình.\nGiao diện VN AIDr - Click để tới video demo\n\nFrontend của phần mềm hiện đang sử dụng sử dụng các framework Bootstrap, Jquery. Phần backend đang sử dụng framework FastAPI. Chúng tôi có dự định chuyển frontend của phần mềm sang sử dụng ReactJS, và đang cần thêm lập trình viên tham gia dự án. Nếu các bạn mong muốn tham gia cùng chúng tôi, cùng xây dựng VN AIDr tốt hơn mỗi ngày, hãy gửi cho chúng tôi một tin nhắn tại trang liên hệ của VNOpenAI.\n2. Luồng hoạt động Chương trình được xây dựng trên nền tảng web. Các mô hình và thuật toán được thiết kế để thực thi trên server. Người dùng sẽ lựa chọn và tải lên các ảnh cần xử lý. Server thực hiện phân tích, xử lý ảnh, thực thi các mô hình ngôn ngữ và trả kết quả về client.\nKiến trúc hệ thống dạng Client - Server của hệ thống\n3. Mã nguồn Toàn bộ mã nguồn của dự án VN AIDr đều được mở cho cộng đồng. Chúng tôi rất hoan nghênh các đóng góp của các bạn cho mã nguồn, mô hình và các ý kiến liên quan đến y học. Mã nguồn có thể được đóng góp trực tiếp bằng cách tạo pull request tại các repo của dự án. Các ý kiến khác có thể được gửi qua Trang liên hệ.\n Mã nguồn của nền tảng VN AIDr: https://github.com/VNOpenAI/vn-aidr.  4. Thiết lập và chạy thử Yêu cầu hệ thống:  Python 3.7 + Pip. Chúng tôi khuyến khích các bạn sử dụng Miniconda hoặc Anaconda. NodeJS. Yarn.  Thiết lập môi trường Clone mã nguồn:\ngit clone https://github.com/VNOpenAI/vn-aidr cd vn-aidr Nếu bạn sử dụng Windows, vui lòng tham khảo cách cài đặt detectron2 cho Windows 10 tại: https://dgmaxime.medium.com/how-to-easily-install-detectron2-on-windows-10-39186139101c.\nCài đặt các gói cần thiết cho server:\npip install -r requirements.txt Cài đặt các gói cần thiết để chỉnh sửa frontend:\ncd frontend yarn Các bước chạy server Khởi server với các lệnh sau:\npython app.py --port=5000 Sau khi server được khởi chạy, mở http://localhost:5000 để vào giao diện web.\nChỉnh sửa frontend Để chỉnh sửa giao diện, cần chạy lệnh sau để liên tục theo dõi và cập nhật các chỉnh sửa liên quan đến giao diện:\ncd frontend yarn start Sau khi chỉnh sửa hoàn tất, chúng ta cần build (sinh) lại giao diện frontend cuối cùng, dùng cho sản phẩm cuối:\ncd frontend yarn build "}),a.add({id:20,href:'/nlp/vn-accent/deep-nn/',title:"Các mô hình học sâu - Thêm dấu tiếng Việt",parent:"Thêm dấu cho báo cáo y tế",content:"1. Lựa chọn mô hình Các mô hình chúng tôi đã thử nghiệm gồm LSTM + Linear, Transformer Encoder + Linear và Evolved Transformer + Linear và theo hướng Word to Word. Các mô hình nhận đầu vào là các từ không dấu (hoặc đã loại bỏ dấu). Với mỗi từ đầu vào, mô hình sẽ phán đoán từ đầu ra là từ nào trong khoảng 9000 từ tiếng Việt (ở đây hiểu là tiếng hoặc từ đơn). Với phương pháp này, số lượng lớp đầu ra khá lớn, ứng với số lượng từ đơn (tiếng) trong tiếng Việt. Một nhược điểm khác của phương pháp này là các từ dự đoán ra có thể khác hẳn từ đầu vào, hay từ đầu vào không phải là dạng bỏ dấu của từ đã cho. Ví dụ khi từ đầu vào là \u0026ldquo;cho\u0026rdquo; thì từ đầu ra hoàn toàn có thể là \u0026ldquo;mèo\u0026rdquo; thay vì là \u0026ldquo;chó\u0026rdquo;. Để khắc phục tình trạng này, thay vì lựa chọn từ có xác suất cao nhất, chúng tôi sắp xếp các từ theo thứ tự giảm dần, sau đó lựa chọn trong các từ dự đoán một từ có xác suất cao nhất mà khi bỏ dấu sẽ thu được từ đầu vào.\nMô hình dạng Word2Word\nChúng tôi cũng đã nghĩ đến phương pháp dự đoán dấu câu cho mỗi từ, thay vì dự đoán một từ đã thêm dấu tương ứng, tuy nhiên chưa có đủ thời gian thử nghiệm. Với cách này, chúng ta có thể giảm số lượng lớp phải dự đoán của mô hình và loại bỏ khả năng dự đoán ra từ khác hẳn với từ đã cho như ở họ mô hình trước. Mô hình dự đoán dấu câu như hình dưới.\nMô hình dạng Word2Tone - dự đoán dấu câu\n1.1. Mô hình LSTM + Linear Các mô hình RNN (Recurrent Neural Network) thường được ứng dụng để xử lý các thông tin dạng chuỗi. Ở đây, mỗi câu không dấu đưa vào có thể coi là một chuỗi, và ứng dụng mô hình RNN để xử lý. So với mạng RNN thuần, LSTM (Long Short-Term Memory) là một cải tiến nhằm hạn chế sự phụ thuộc xa (long-term dependencies) và vanishing gradient. Nó khiến việc học trở nên hiệu quả hơn nhiều các mạng RNN truyền thống. Kiến trúc LSTM được chúng tôi cài đặt kết hợp với lớp Linear (Fully connected) như hình dưới để dự đoán từ có dấu dựa vào từ không dầu.\nLSTM cho thêm dấu Tiếng Việt\nMô hình LSTM trên là mô hình baseline đơn giản nhất ứng dụng học sâu để thêm dấu tiếng Việt. Từ mô hình này, chúng tôi cải tiến và triển khai thêm mô hình LSTM hai chiều (Bi-directional LSTM) để tăng độ chính xác. Mô hình Bi-directional LSTM được chúng tôi cài đặt như sau.\nBidirectional LSTM cho thêm dấu Tiếng Việt\n1.2. Mô hình Transformer Thiết kế chung của Transformer Các mô hình RNN, GRU (Gated Recurrent Unit), LSTM hay các cải tiến khác về sau được sử dụng kết hợp với cơ chế attention để cải thiện thêm độ chính xác. Sau này, kiến trúc Transformer ra đời đưa ra một thiết kế hoàn toàn mới - chỉ sử dụng cơ chế attention mà không cần sử dụng các mạng tích chập (CNN) hoặc hồi tiếp (RNN) làm đầu vào. Kiến trúc của Transformer được thể hiện trong hình dưới.\nKiến trúc Transformer - Hình ảnh từ cuốn Dive into Deep learning - https://d2l.ai/chapter_attention-mechanisms/transformer.html\nTransformer được thiết kế dựa trên kiến trúc Encoder-Decoder. Có thể hiểu đơn giản, khối Encoder có khả năng tổng hợp thông tin từ đầu vào. Đầu ra của khối Encoder là đầu vào của khối Decoder. Khối Decoder sẽ dựa vào các thông tin tổng hợp được từ Encoder để đưa ra suy luận cho kết quả đầu ra.\nỞ Transformer, chúng ta không thấy có dự xuất hiện của các khối mạng hồi tiếp để giữ thông tin về vị trí. Thay vào đó. Các tác giả sử dụng khổi Positional encoding để mã hoá thông tin vị trí vào giá trị đầu vào. Tiếp đó, mô hình sử dụng cơ chế multi-head attention để giúp mô hình có thể \u0026ldquo;attention\u0026rdquo; (chú ý) vào nhiều vị trí, đồng thời cũng có thể ánh xạ biểu diễn theo nhiều cách khác nhau thông qua nhiều bộ giá trị Query/Key/Value.\nSử dụng Transformer trong bài toán thêm dấu tiếng Việt Chúng tôi chỉ sử dụng phần Encoder của mô hình Transformer cho bài toán của mình, sau đó kết hợp với một lớp Linear (Fully connected) và cho ra kết quả. Mô hình được mô tả như hình vẽ dưới.\nTransformer Encoder cho thêm dấu Tiếng Việt\n1.3. Mô hình Evolved Transformer Thiết kế chung của Evolved Transformer Mô hình Evolved Transformer là một bản cải tiến của Transformer bằng cách sử dụng phương pháp tìm kiếm kiến trúc mạng NAS (neural architecture search) để cải tiến kiến trúc cũ. Dưới đây là một số khác biệt của Envolved Transformer so với Transformer nguyên bản.\nKhác biệt của Evolved Transformer so với Transformer ở phần Encoder - Hình ảnh từ bài báo Evolved Transformer\nKhác biệt của Evolved Transformer so với Transformer ở phần Decoder - Hình ảnh từ bài báo Evolved Transformer\nSử dụng Evolved Transformer trong bài toán thêm dấu tiếng Việt Chúng tôi cũng sử dụng phần Encoder của mô hình Evolved Transformer cho bài toán của mình, sau đó kết hợp với một lớp Linear (Fully connected) và cho ra kết quả. Mô hình được mô tả như hình vẽ dưới.\nEvolved Transformer Encoder cho thêm dấu Tiếng Việt\n2. Tokenizer Để huấn luyện mô hình, chúng ta phải đưa vào dữ liệu dạng số. Chúng ta sẽ tạo một tham chiếu từ 1 từ sang 1 số và đưa vào mô hình dạng số của mỗi từ. Tham chiếu này được gọi là tokenizer. Khái niệm từ ở đây giống ở tiếng Anh, tức là tương đương một tiếng, hay từ đơn ở trong tiếng Việt. Chúng tôi không dùng tokenizer tạo từ các tập data trên mà dùng một danh sách từ lấy tại vietnamese-wordlist để tạo bộ tokenizer bằng cách cắt các từ trong đó và chọn lại các từ đơn. Kết quả được khoảng 9000 từ có dấu, tương đương với khoảng 3000 từ đã bỏ dấu. Bộ tokenizer ở đây được xây dựng đơn giản bằng cách tham chiếu một từ với số thứ tự của nó trong danh sách thu được.\n3. Kết quả thử nghiệm 3.1. Độ đo đánh giá mô hình Độ chính xác của mô hình được tính bằng công thức $Acc = R / N$, trong đó $R$ là số chữ được dự đoán đúng dâu câu, $N$ là tổng số chữ trong văn bản.\n3.2. Kết quả Kết quả kiểm thử (độ chính xác) trên tập giám sát (validation) của các mô hình như sau.\n   Mô hình Tham số huấn luyện Độ chính xác     Large BiLSTM Adam, betas=(0.9, 0.98), lr=1e-4, epochs=19 95.90%   Transformer Adam, betas=(0.9, 0.98), lr=3e-4, epochs=26 84.59%   Evolved Transformer Adam, betas=(0.9, 0.98), lr=3e-4, epochs=15 98.12%    Như vậy, mô hình này đạt độ chính xác tốt nhất trong các mô hình chúng tôi đã triển khai. Mô hình này đạt độ chính xác 98.07% trên tập kiểm thử (test set).\n*Hình ảnh được lấy từ slide: slides/vnopenai-vn-accent.pptx\n"}),a.add({id:21,href:'/nlp/vn-accent/deployment/',title:"Triển khai - Thêm dấu tiếng Việt",parent:"Thêm dấu cho báo cáo y tế",content:"Khi triển khai lên phần mềm VN AIDr, chúng tôi viết thêm các đoạn mã tiền/hậu xử lý để việc thêm dấu giữ lại được đúng định dạng đầu vào của văn bản như vị trí chữ cần thêm dấu, định dạng hoa/thường, các ký tự đặc biệt\u0026hellip; Dưới đây là một số màn hình khi các mô hình được triển khai vào VN AIDr.\nMàn hình nhập nhận xét bác sĩ – Không dấu\nSau khi bác sĩ ấn Add Accent, dấu câu sẽ được thêm vào\n"}),a.add({id:22,href:'/vision/skin-lesion-segmentation/source-code/',title:"Mã nguồn khoanh vùng tổn thương trên da",parent:"Phân vùng tổn thương da",content:"Toàn bộ mã nguồn của dự án VN AIDr đều được mở cho cộng đồng. Chúng tôi rất hoan nghênh các đóng góp của các bạn cho mã nguồn, mô hình và các ý kiến liên quan đến y học. Mã nguồn có thể được đóng góp trực tiếp bằng cách tạo pull request tại các repo của dự án. Các ý kiến khác có thể được gửi qua Trang liên hệ.\n Mã nguồn huấn luyện: https://github.com/VNOpenAI/skin-lesion-segmentation.  "}),a.add({id:23,href:'/vision/lung-abnormalities-detection-xray/source-code/',title:"Mã nguồn phát hiện bất thường trên phổi từ ảnh x-quang",parent:"Phát hiện bất thường trên phổi",content:"Toàn bộ mã nguồn của dự án VN AIDr đều được mở cho cộng đồng. Chúng tôi rất hoan nghênh các đóng góp của các bạn cho mã nguồn, mô hình và các ý kiến liên quan đến y học. Mã nguồn có thể được đóng góp trực tiếp bằng cách tạo pull request tại các repo của dự án. Các ý kiến khác có thể được gửi qua Trang liên hệ.\n Mã nguồn huấn luyện: https://www.kaggle.com/vietanhdev/vinbigdata-cxr-ad-yolov5-14-class-train?scriptVersionId=52123826.  "}),a.add({id:24,href:'/vision/lung-abnormalities-classification-xray/source-code/',title:"Mã nguồn phân loại bất thường trên phổi từ ảnh x-quang",parent:"Phân loại tổn thương phổi",content:"Toàn bộ mã nguồn của dự án VN AIDr đều được mở cho cộng đồng. Chúng tôi rất hoan nghênh các đóng góp của các bạn cho mã nguồn, mô hình và các ý kiến liên quan đến y học. Mã nguồn có thể được đóng góp trực tiếp bằng cách tạo pull request tại các repo của dự án. Các ý kiến khác có thể được gửi qua Trang liên hệ.\n Mã nguồn huấn luyện: https://github.com/thanhtran98/chexpert_pytorch_base.  "}),a.add({id:25,href:'/nlp/vn-accent/source-code/',title:"Mã nguồn thêm dấu tiếng Việt",parent:"Thêm dấu cho báo cáo y tế",content:"Toàn bộ mã nguồn của dự án VN AIDr đều được mở cho cộng đồng. Chúng tôi rất hoan nghênh các đóng góp của các bạn cho mã nguồn, mô hình và các ý kiến liên quan đến y học. Mã nguồn có thể được đóng góp trực tiếp bằng cách tạo pull request tại các repo của dự án. Các ý kiến khác có thể được gửi qua Trang liên hệ.\n Mã nguồn huấn luyện: https://github.com/VNOpenAI/vn-accent.  "}),a.add({id:26,href:'/categories/',title:"Categories",parent:"VN AIDr",content:""}),a.add({id:27,href:'/tags/',title:"Tags",parent:"VN AIDr",content:""}),a.add({id:28,href:'/',title:"VN AIDr",parent:'',content:"VN AIDr là dự án xử lý ảnh y tế mã nguồn mở xây dựng bởi nhóm VNOpenAI. Chúng tôi xây dựng dự án này trên nền tảng một phần mềm xử lý ảnh y tế nguồn mở (VAD Platform). Trên VAD Platform, chúng tôi triển khai VAD Vision bao gồm các mô hình và các thuật toán xử lý ảnh y tế. Chúng tôi cũng triển khai một mô-đun xử lý ngôn ngữ tự nhiên là VAD NLP, với chức năng tự động hoàn thành các báo cáo y tế. Dựa trên nền tảng phần mềm và mô hình phía dưới, chúng tôi xây dựng các tài liệu về xử lý ảnh y tế và xử lý ngôn ngữ tự nhiên nhằm giúp học sinh, sinh viên và những người yêu thích có thể tiếp cận các lĩnh vực này dựa trên các bài toán cụ thể.\n--    Liên hệ VNOpenAI luôn chào đón các đóng góp từ cộng đồng để xây dựng dự án ngày càng hoàn thiện hơn. Đóng góp của các bạn có thể là việc giúp chúng tôi phát triển thêm các chức năng mới, tích hợp mô hình, sửa lỗi phần mềm, hoặc những đánh giá về hiệu năng phần mềm và góp ý về các chức năng cần có từ góc nhìn của các bác sĩ, sinh viên ngành y. Xin vui lòng liên hệ:\nNhóm VNOpenAI\n Website: https://vnopenai.org/. Email: vnopenai@gmail.com.  *Hình ảnh được lấy từ slide: slides/vnopenai-vn-accent.pptx\n"})})()